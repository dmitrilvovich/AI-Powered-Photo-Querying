# AI-Powered-Photo-Querying (In Progress)
Accessible through this link : https://dmitrilvovich.github.io/AI-Powered-Photo-Querying/

A proof-of-concept web application that allows users to query images using natural languge queries. For instance, typing "get me all my cat pictures" will display all cat pictures in the gallery.
The app uses the OpenAI API to process the queries, which compares the natural language input with detailed descriptions of the images (generated by the OpenAI API) and returns a list of the most relevant images, which then get displayed on the web application.

# Current Issues and Limitations
As the current version is still a first makeshift upload, the code does contain a few hiccups:
1. The program does not currently save previous queries and results. This means subsequent querying/filtering after an initial query are treated as initial queries. I will add code to save query history such that multi-step queries will be possible.
2. The app does not have any image upload features at the moment. I am planning on implementing this by having any image upload go through a safety check using the OpenAI API before saving the image and making a descripition of the image (to prevent any inappropriate images to show up).
3. Only 2 images are uploaded to the app at the moment, which eliminates the convenience of my app. I will upload more once I get the time.
4. The OpenAI API bills are largely based on the amount of data sent to the API. As you can imagine, this means that sending all those detailed image descriptions can be relatively costly. My current plan is to have OpenAI return shorter descriptions by asking for detailed descriptions using key words. Future versions might also get rid of the problem much more effectively.

# Future Versions
My goal for this project is to make it as efficient and accurate as possible. My main concern is that as the gallery grows in size, the computation time also grows very noticably (the OpenAI API bills would also reflect this).
As I move forward with this project, there might come a time where I completely change the querying process to achieve my goal. For instance, I could assign each image a vector based on their descriptions and display all image that match a vector query (a user query turned to a vector). This would eliminate the need for the OpenAi API during the querying process (therefore increase efficiency) and we would then only need it for the image description-making process. My concern with this method is reduced accuracy, as I believe OpenAI would most likely be more accurate in finding matches than this proposed idea. Alternatively, I could use the vector method for high-volume querying, and OpenAI for lower-volume querying.
